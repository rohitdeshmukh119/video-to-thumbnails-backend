// src/video/schemas/video.schema.ts
import { Prop, Schema, SchemaFactory } from '@nestjs/mongoose';
import { Document, Types } from 'mongoose'; // Ensure Types is imported for ObjectId or other Mongoose types

// Interface for the scenes identified by Gemini
// This is exported so it can be used for type hinting in services or other modules
export interface IdentifiedSceneSubdocument {
  timestamp: number;
  description?: string;
  frameLocalPaths?: string[]; // Paths to the frames extracted for this scene (t-1s, t, t+1s)
}

// Interface for the output images generated by RunwayML
// This is also exported for type hinting
@Schema() // Schema for the subdocument
export class RunwayOutputImageSubdocument {
  @Prop({ required: true })
  originalVideoFramePath: string; // Path to the frame from the original video used as input

  @Prop({ required: true })
  userTextInput: string;          // The text prompt used by the user for RunwayML

  @Prop({ type: String, required: false }) // Optional path to user-provided input image
  userInputImagePath?: string;    // Optional: Path to the user-provided input image (from frontend)

  @Prop({ required: true })
  runwayOutputImagePath: string;  // Path to the final image generated by RunwayML (URL or local path)

  @Prop({ type: Date, default: Date.now }) // Timestamp when this RunwayML processing occurred
  processedAt: Date;
}
const RunwayOutputImageSchema = SchemaFactory.createForClass(RunwayOutputImageSubdocument);


@Schema({ timestamps: true }) // `timestamps: true` automatically adds `createdAt` and `updatedAt` fields
export class Video {
  @Prop({ required: true })
  originalFileName: string;

  @Prop({ required: true })
  mimeType: string;

  @Prop({ required: true })
  localFilePath: string;

  @Prop({ required: true })
  userPrompt: string;

  // Current status of the video processing workflow
  @Prop({
    type: String,
    enum: ['PENDING', 'PROCESSING', 'COMPLETED', 'FAILED', 'RUNWAY_PENDING', 'RUNWAY_COMPLETED', 'RUNWAY_FAILED'],
    default: 'PENDING',
    required: true
  })
  status: string;

  // Array of scenes identified by the Gemini API, including paths to extracted frames
  @Prop({
    type: [
      {
        timestamp: Number,
        description: String,
        frameLocalPaths: [String] // Array of strings for frame paths
      }
    ],
    default: []
  })
  identifiedScenes: IdentifiedSceneSubdocument[]; // Type-hinted with the interface

  // Array of images generated by RunwayML, including their metadata and paths
  @Prop({
    type: [RunwayOutputImageSchema], // Use the schema for the subdocument
    default: []
  })
  runwayGeneratedImages: Types.Array<RunwayOutputImageSubdocument>; // Type-hinted with the new class/interface

  // Stores an error message if processing fails at any stage
  @Prop({ type: String, required: false })
  processingError?: string;
}

// Create the Mongoose Schema from the Video class
export const VideoSchema = SchemaFactory.createForClass(Video);

// Type alias for a Mongoose Document that has the Video schema's properties
export type VideoDocument = Video & Document;